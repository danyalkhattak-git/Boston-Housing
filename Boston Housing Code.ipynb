{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8bf029a-07bb-4eda-9049-a6b3462893bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
      "\n",
      "   PTRATIO  LSTAT  MEDV  \n",
      "0     15.3   4.98  24.0  \n",
      "1     17.8   9.14  21.6  \n",
      "2     17.8   4.03  34.7  \n",
      "3     18.7   2.94  33.4  \n",
      "4     18.7   5.33  36.2  \n",
      "Number of rows: 506\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "# By: Danyal Khattak\n",
    "\n",
    "#%%\n",
    "\n",
    "### Data Cleaning: Part - a\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Column names from description\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \n",
    "                'DIS', 'RAD', 'TAX', 'PTRATIO', 'LSTAT', 'MEDV']\n",
    "\n",
    "# Loading the CSV file, specifying no header and assigning column names\n",
    "bh = pd.read_csv('boston_housing_mid.csv', header=None, names=column_names)\n",
    "\n",
    "# Displaying the top 5 lines \n",
    "print(bh.head())\n",
    "\n",
    "# Displaying the number of rows and columns\n",
    "print(\"Number of rows:\", bh.shape[0])\n",
    "print(\"Number of columns:\", bh.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cdbdde-a875-4bd1-94e0-0eb097ed9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "### Data Cleaning: Part - b\n",
    "\n",
    "print(bh.dtypes)\n",
    "bh['RAD'] = bh['RAD'].astype('float64')\n",
    "bh['CHAS'] = bh['CHAS'].astype('bool')\n",
    "\n",
    "print(bh.dtypes)\n",
    "\n",
    "#%%\n",
    "### Data Cleeaning: Part - c\n",
    "\n",
    "# Identifying missing values and their counts\n",
    "missing_values_count = bh.isna().sum()\n",
    "\n",
    "# Displaying only attributes with missing values\n",
    "print(missing_values_count[missing_values_count > 0])\n",
    "\n",
    "# Making copies of the dataset for each of the method for removing the null values. \n",
    "bh_del_col = bh.copy()\n",
    "bh_del_row = bh.copy()\n",
    "bh_null_0 = bh.copy()\n",
    "bh_null_ffill = bh.copy()\n",
    "\n",
    "# 1. Dropping each column with a null value\n",
    "bh_del_col.dropna(axis=1, inplace=True)\n",
    "print(bh_del_col)\n",
    "bh_del_col.info()\n",
    "\n",
    "\n",
    "# 2. Dropping each row with a null value.\n",
    "bh_del_row.dropna(inplace=True)\n",
    "print(bh_del_row)\n",
    "bh_del_row.info()\n",
    "\n",
    "\n",
    "# 3. Replacing null values with 0.\n",
    "bh_null_0.fillna(0, inplace=True)\n",
    "print(bh_null_0)\n",
    "bh_null_0.info()\n",
    "\n",
    "# 4. Writing a function that replaces the null values with mean of 2 rows above and below the null value.  \n",
    "bh_null_ffill['NOX'].fillna(method='ffill', inplace=True)\n",
    "print(bh_null_ffill[['NOX']])  \n",
    "bh_null_ffill.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec84408-bf29-4dd6-981b-ff4bfc2dec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "### Preparation for analysis: Part - a\n",
    "\n",
    "## (I)\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "# 1. Creating the 'NOX_cat' \n",
    "bh['NOX_cat'] = pd.cut(bh_null_ffill['NOX'], bins=9, labels=range(1, 10))\n",
    "\n",
    "# 2. Using Stratified Shuffle Split on 'NOX_cat'\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.22, random_state=42) \n",
    "for train_index, test_index in split.split(bh, bh['NOX_cat']):\n",
    "    bh_train_set = bh.loc[train_index]\n",
    "    bh_test_set = bh.loc[test_index]\n",
    "    \n",
    "\n",
    "## (II)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creating histograms\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "bh['NOX_cat'].hist(bins=9) \n",
    "plt.title('Original Dataset')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bh_test_set['NOX_cat'].hist(bins=9) \n",
    "plt.title('Stratified Test Set')\n",
    "\n",
    "plt.suptitle(\"NOX_cat Distribution\")\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6552ea-2b8f-40a8-80bb-c9bd695f7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (III)\n",
    "\n",
    "# Proportions in the training set\n",
    "train_proportions = bh_train_set['NOX_cat'].value_counts() / len(bh_train_set)\n",
    "\n",
    "# Proportions in the Original set\n",
    "test_proportions = bh_test_set['NOX_cat'].value_counts() / len(bh_test_set)\n",
    "\n",
    "# Printing for comparison\n",
    "print(\"Training Set Proportions:\\n\", train_proportions)\n",
    "print(\"Test Set Proportions:\\n\", test_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e68d8-28bd-4050-9c45-d19af1ce7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (IV)\n",
    "\n",
    "# Removing 'NOX_cat' column\n",
    "for set_ in (bh, bh_train_set, bh_test_set): \n",
    "    set_.drop(\"NOX_cat\", axis=1, inplace=True)\n",
    "\n",
    "# Printing shapes\n",
    "print(\"Shape of Training Set:\", bh_train_set.shape)\n",
    "print(\"Shape of Test Set:\", bh_test_set.shape)\n",
    "print(\"Shape of Original Dataset:\", bh.shape)\n",
    "\n",
    "# Calculating the ratio of the length of the test set to that of the original\n",
    "test_set_ratio = len(bh_test_set) / len(bh) * 100\n",
    "print(\"Test Set Ratio:\", test_set_ratio, \"%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790918ec-6255-4e3e-a986-f67bfb30daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "### Data Analysis\n",
    "\n",
    "\n",
    "\n",
    "## (I)\n",
    "correlation_matrix = bh_train_set.corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "\n",
    "\n",
    "## (II)\n",
    "# Calculating correlations with 'MEDV'\n",
    "correlation_medv = bh_train_set.corr()['MEDV']\n",
    "\n",
    "# Sorting in descending order\n",
    "MEDV_sorted_correlations = correlation_medv.sort_values(ascending=False)\n",
    "\n",
    "print(MEDV_sorted_correlations)\n",
    "\n",
    "\n",
    "\n",
    "## (III)\n",
    "MEDV_Scatter = ['MEDV', 'INDUS', 'NOX','LSTAT','RM']\n",
    "\n",
    "# Creating the scatter matrix for MEDV, INDUS, NOX, LSTAT, and RM\n",
    "pd.plotting.scatter_matrix(bh[MEDV_Scatter], figsize=(10, 10))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "## (IV)\n",
    "AGE_Scatter = ['MEDV', 'AGE']\n",
    "\n",
    "# Creating the scatter matrix for MEDV vs AGE\n",
    "pd.plotting.scatter_matrix(bh[AGE_Scatter], figsize=(10, 10))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## (IV)\n",
    "AGE_RM_Scatter = ['RM', 'AGE']\n",
    "\n",
    "# Creating the scatter matrix for RM and AGE\n",
    "pd.plotting.scatter_matrix(bh[AGE_RM_Scatter], figsize=(10, 10))\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
